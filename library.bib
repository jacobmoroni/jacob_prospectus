Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@article{Hornung2013,
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornung et al. - 2013 - OctoMap an efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
month = {apr},
number = {3},
pages = {189--206},
publisher = {Springer US},
title = {{OctoMap: an efficient probabilistic 3D mapping framework based on octrees}},
url = {http://link.springer.com/10.1007/s10514-012-9321-0},
volume = {34},
year = {2013}
}
@inproceedings{Bryson2007,
author = {Bryson, Mitch and Sukkarieh, Salah},
booktitle = {2007 IEEE Aerospace Conference},
doi = {10.1109/AERO.2007.352850},
isbn = {1-4244-0524-6},
pages = {1--12},
publisher = {IEEE},
title = {{Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments}},
url = {http://ieeexplore.ieee.org/document/4161346/},
year = {2007}
}
@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@article{Labbe2013,
abstract = {In appearance-based localization and mapping, loop- closure detection is the process used to determinate if the cur- rent observation comes from a previously visited location or a new one. As the size of the internal map increases, so does the time required to compare new observations with all stored loca- tions, eventually limiting online processing. This paper presents an online loop-closure detection approach for large-scale and long- term operation. The approach is based on amemorymanagement method,which limits the number of locations used for loop-closure detection so that the computation time remains under real-time constraints. The idea consists of keeping the most recent and fre- quently observed locations in a working memory (WM) that is used for loop-closure detection, and transferring the others into a long-term memory (LTM). When a match is found between the current location and one stored in WM, associated locations that are stored in LTM can be updated and remembered for addi- tional loop-closure detections. Results demonstrate the approach's adaptability and scalability using ten standard datasets from other appearance-based loop-closure approaches, one custom dataset us- ing real images taken over a 2-km loop of our university campus, and one custom dataset (7 h) using virtual images from the racing video game “Need for Speed:MostWanted.”},
author = {Labbe, Mathieu and Michaud, Francois},
doi = {10.1109/TRO.2013.2242375},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Appearance-Based Loop Closure Detection for Online Large-Scale and Long-Term Operation.pdf:pdf},
isbn = {978-1-61284-455-8},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Appearance-based localization and mapping,bag-of-words approach,dynamic Bayes filtering,place recognition},
number = {3},
pages = {734--745},
pmid = {6459608},
title = {{Appearance-based loop closure detection for online large-scale and long-term operation}},
url = {https://introlab.3it.usherbrooke.ca/mediawiki-introlab/images/b/bc/TRO2013.pdf},
volume = {29},
year = {2013}
}
@article{Ellekilde2007,
author = {Ellekilde, Lars-Peter and Huang, Shoudong and {Valls Mir{\'{o}}}, Jaime and Dissanayake, Gamini},
doi = {10.1002/rob.20173},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {jan},
number = {1-2},
pages = {71--89},
title = {{Dense 3D Map Construction for Indoor Search and Rescue}},
url = {http://doi.wiley.com/10.1002/rob.20173},
volume = {24},
year = {2007}
}
@article{Zou2013,
abstract = {This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce intercamera pose estimation and intercamera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.},
author = {Zou, Danping and Tan, Ping},
doi = {10.1109/TPAMI.2012.104},
isbn = {2011100712},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Visual SLAM,dynamic environments,structure-from-motion,swarm},
month = {feb},
number = {2},
pages = {354--366},
pmid = {22547430},
title = {{CoSLAM: Collaborative visual SLAM in dynamic environments}},
url = {http://ieeexplore.ieee.org/document/6193110/},
volume = {35},
year = {2013}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@article{Wheeler2017,
author = {Wheeler, David and Koch, Daniel and Jackson, James and Ellingson, Gary and Nyholm, Paul and McLain, Timothy and Beard, Randal},
journal = {All Faculty Publications},
month = {aug},
title = {{Relative Navigation of Autonomous GPS-Degraded Micro Air Vehicles}},
url = {https://scholarsarchive.byu.edu/facpub/1962},
year = {2017}
}
@article{Henry2010,
abstract = {RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.},
author = {Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
doi = {10.1177/0278364911434148},
journal = {The International Journal of Robotics Research},
keywords = {RGB-D,SLAM,kinect,localization,mapping,range sensing,vision},
number = {5},
pages = {647--663},
title = {{RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments}},
url = {http://journals.sagepub.com/doi/pdf/10.1177/0278364911434148},
volume = {31},
year = {2010}
}
@article{Michael2012,
author = {Michael, Nathan and Shen, Shaojie and Mohta, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
doi = {10.1002/rob.21436},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michael et al. - 2012 - Collaborative mapping of an earthquake-damaged building via ground and aerial robots.pdf:pdf},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {sep},
number = {5},
pages = {832--841},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Collaborative mapping of an earthquake-damaged building via ground and aerial robots}},
url = {http://doi.wiley.com/10.1002/rob.21436},
volume = {29},
year = {2012}
}
@article{Michael2012,
author = {Michael, Nathan and Shen, Shaojie and Mohta, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
doi = {10.1002/rob.21436},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michael et al. - 2012 - Collaborative mapping of an earthquake-damaged building via ground and aerial robots.pdf:pdf},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {sep},
number = {5},
pages = {832--841},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Collaborative mapping of an earthquake-damaged building via ground and aerial robots}},
url = {http://doi.wiley.com/10.1002/rob.21436},
volume = {29},
year = {2012}
}
@article{Henry2010a,
abstract = {RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.},
author = {Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
doi = {10.1177/0278364911434148},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henry et al. - 2010 - RGB-D mapping Using Kinect-style depth cameras for dense 3D modeling of indoor environments.pdf:pdf},
journal = {The International Journal of Robotics Research},
keywords = {RGB-D,SLAM,kinect,localization,mapping,range sensing,vision},
number = {5},
pages = {647--663},
title = {{RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments}},
url = {http://journals.sagepub.com/doi/pdf/10.1177/0278364911434148},
volume = {31},
year = {2010}
}
@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@misc{Luotsinen2004,
author = {Luotsinen, Linus J and Gonzalez, Avelino J and Boeloeni, Ladislau},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luotsinen, Gonzalez, Boeloeni - 2004 - Collaborative UAV Exploration of Hostile Environments.pdf:pdf},
keywords = {*ALGORITHMS,*AUTONOMOUS NAVIGATION,*COMBAT AREAS,*SURVEILLANCE DRONES,*TACTICAL DATA SYSTEMS,ADVERSE CONDITIONS,ARTIFICIAL INTELLIGENCE,COLLABORATIVE TECHNIQUES,COMPUTERIZED SIMULATION,DECISION MAKING,GRIDS(COORDINATES),INFORMATION TRANSFER,MAPS,SYMPOSIA},
title = {{Collaborative UAV Exploration of Hostile Environments}},
url = {http://www.dtic.mil/docs/citations/ADA432922},
year = {2004}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@article{Hornung2013,
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornung et al. - 2013 - OctoMap an efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
month = {apr},
number = {3},
pages = {189--206},
publisher = {Springer US},
title = {{OctoMap: an efficient probabilistic 3D mapping framework based on octrees}},
url = {http://link.springer.com/10.1007/s10514-012-9321-0},
volume = {34},
year = {2013}
}
@article{Ellekilde2007,
author = {Ellekilde, Lars-Peter and Huang, Shoudong and {Valls Mir{\'{o}}}, Jaime and Dissanayake, Gamini},
doi = {10.1002/rob.20173},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {jan},
number = {1-2},
pages = {71--89},
title = {{Dense 3D Map Construction for Indoor Search and Rescue}},
url = {http://doi.wiley.com/10.1002/rob.20173},
volume = {24},
year = {2007}
}
@article{Wheeler2017,
author = {Wheeler, David and Koch, Daniel and Jackson, James and Ellingson, Gary and Nyholm, Paul and McLain, Timothy and Beard, Randal},
journal = {All Faculty Publications},
month = {aug},
title = {{Relative Navigation of Autonomous GPS-Degraded Micro Air Vehicles}},
url = {https://scholarsarchive.byu.edu/facpub/1962},
year = {2017}
}
@inproceedings{Bryson2007,
author = {Bryson, Mitch and Sukkarieh, Salah},
booktitle = {2007 IEEE Aerospace Conference},
doi = {10.1109/AERO.2007.352850},
isbn = {1-4244-0524-6},
pages = {1--12},
publisher = {IEEE},
title = {{Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments}},
url = {http://ieeexplore.ieee.org/document/4161346/},
year = {2007}
}
@article{Zou2013,
abstract = {This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce intercamera pose estimation and intercamera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.},
author = {Zou, Danping and Tan, Ping},
doi = {10.1109/TPAMI.2012.104},
isbn = {2011100712},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Visual SLAM,dynamic environments,structure-from-motion,swarm},
month = {feb},
number = {2},
pages = {354--366},
pmid = {22547430},
title = {{CoSLAM: Collaborative visual SLAM in dynamic environments}},
url = {http://ieeexplore.ieee.org/document/6193110/},
volume = {35},
year = {2013}
}
@article{Labbe2013,
abstract = {In appearance-based localization and mapping, loop- closure detection is the process used to determinate if the cur- rent observation comes from a previously visited location or a new one. As the size of the internal map increases, so does the time required to compare new observations with all stored loca- tions, eventually limiting online processing. This paper presents an online loop-closure detection approach for large-scale and long- term operation. The approach is based on amemorymanagement method,which limits the number of locations used for loop-closure detection so that the computation time remains under real-time constraints. The idea consists of keeping the most recent and fre- quently observed locations in a working memory (WM) that is used for loop-closure detection, and transferring the others into a long-term memory (LTM). When a match is found between the current location and one stored in WM, associated locations that are stored in LTM can be updated and remembered for addi- tional loop-closure detections. Results demonstrate the approach's adaptability and scalability using ten standard datasets from other appearance-based loop-closure approaches, one custom dataset us- ing real images taken over a 2-km loop of our university campus, and one custom dataset (7 h) using virtual images from the racing video game “Need for Speed:MostWanted.”},
author = {Labbe, Mathieu and Michaud, Francois},
doi = {10.1109/TRO.2013.2242375},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Appearance-Based Loop Closure Detection for Online Large-Scale and Long-Term Operation.pdf:pdf},
isbn = {978-1-61284-455-8},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Appearance-based localization and mapping,bag-of-words approach,dynamic Bayes filtering,place recognition},
number = {3},
pages = {734--745},
pmid = {6459608},
title = {{Appearance-based loop closure detection for online large-scale and long-term operation}},
url = {https://introlab.3it.usherbrooke.ca/mediawiki-introlab/images/b/bc/TRO2013.pdf},
volume = {29},
year = {2013}
}
