Automatically generated by Mendeley Desktop 1.18
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Mangelson2018,
abstract = {— This paper reports on a method for robust se-lection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an " odometry back-bone " to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Max-imization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in real-time. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.},
author = {Mangelson, Joshua G and Dominic, Derrick and Eustice, Ryan M and Vasudevan, Ram},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangelson et al. - Unknown - Pairwise Consistent Measurement Set Maximization for Robust Multi-robot Map Merging(2).pdf:pdf},
isbn = {9781538630808},
journal = {ICRA 2018},
title = {{Pairwise Consistent Measurement Set Maximization for Robust Multi-robot Map Merging}},
url = {http://robots.engin.umich.edu/{~}joshuagm/pubs/jmangelson-2018a.pdf},
year = {2018}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@misc{Velodyne,
author = {Velodyne},
title = {{VLP-16 Velodyne LiDAR}},
url = {http://velodynelidar.com/vlp-16.html},
urldate = {2018-06-18}
}
@misc{Intel,
author = {Intel},
title = {{Intel{\textregistered} RealSense™ Depth Camera D435 - Intel{\textregistered} RealSense™ Depth Cameras}},
url = {https://click.intel.com/intelr-realsensetm-depth-camera-d435.html},
urldate = {2018-06-18}
}
@inproceedings{Bryson2007,
author = {Bryson, Mitch and Sukkarieh, Salah},
booktitle = {2007 IEEE Aerospace Conference},
doi = {10.1109/AERO.2007.352850},
isbn = {1-4244-0524-6},
pages = {1--12},
publisher = {IEEE},
title = {{Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments}},
url = {http://ieeexplore.ieee.org/document/4161346/},
year = {2007}
}
@article{Labbe2013,
abstract = {In appearance-based localization and mapping, loop- closure detection is the process used to determinate if the cur- rent observation comes from a previously visited location or a new one. As the size of the internal map increases, so does the time required to compare new observations with all stored loca- tions, eventually limiting online processing. This paper presents an online loop-closure detection approach for large-scale and long- term operation. The approach is based on amemorymanagement method,which limits the number of locations used for loop-closure detection so that the computation time remains under real-time constraints. The idea consists of keeping the most recent and fre- quently observed locations in a working memory (WM) that is used for loop-closure detection, and transferring the others into a long-term memory (LTM). When a match is found between the current location and one stored in WM, associated locations that are stored in LTM can be updated and remembered for addi- tional loop-closure detections. Results demonstrate the approach's adaptability and scalability using ten standard datasets from other appearance-based loop-closure approaches, one custom dataset us- ing real images taken over a 2-km loop of our university campus, and one custom dataset (7 h) using virtual images from the racing video game “Need for Speed:MostWanted.”},
author = {Labbe, Mathieu and Michaud, Francois},
doi = {10.1109/TRO.2013.2242375},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Appearance-Based Loop Closure Detection for Online Large-Scale and Long-Term Operation.pdf:pdf},
isbn = {978-1-61284-455-8},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Appearance-based localization and mapping,bag-of-words approach,dynamic Bayes filtering,place recognition},
number = {3},
pages = {734--745},
pmid = {6459608},
title = {{Appearance-based loop closure detection for online large-scale and long-term operation}},
url = {https://introlab.3it.usherbrooke.ca/mediawiki-introlab/images/b/bc/TRO2013.pdf},
volume = {29},
year = {2013}
}
@article{Hornung2013,
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornung et al. - 2013 - OctoMap an efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
month = {apr},
number = {3},
pages = {189--206},
publisher = {Springer US},
title = {{OctoMap: an efficient probabilistic 3D mapping framework based on octrees}},
url = {http://link.springer.com/10.1007/s10514-012-9321-0},
volume = {34},
year = {2013}
}
@article{Wheeler2017,
author = {Wheeler, David and Koch, Daniel and Jackson, James and Ellingson, Gary and Nyholm, Paul and McLain, Timothy and Beard, Randal},
journal = {All Faculty Publications},
month = {aug},
title = {{Relative Navigation of Autonomous GPS-Degraded Micro Air Vehicles}},
url = {https://scholarsarchive.byu.edu/facpub/1962},
year = {2017}
}
@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@article{Zou2013,
abstract = {This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce intercamera pose estimation and intercamera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.},
author = {Zou, Danping and Tan, Ping},
doi = {10.1109/TPAMI.2012.104},
isbn = {2011100712},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Visual SLAM,dynamic environments,structure-from-motion,swarm},
month = {feb},
number = {2},
pages = {354--366},
pmid = {22547430},
title = {{CoSLAM: Collaborative visual SLAM in dynamic environments}},
url = {http://ieeexplore.ieee.org/document/6193110/},
volume = {35},
year = {2013}
}
@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@article{Michael2012,
author = {Michael, Nathan and Shen, Shaojie and Mohta, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
doi = {10.1002/rob.21436},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michael et al. - 2012 - Collaborative mapping of an earthquake-damaged building via ground and aerial robots.pdf:pdf},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {sep},
number = {5},
pages = {832--841},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Collaborative mapping of an earthquake-damaged building via ground and aerial robots}},
url = {http://doi.wiley.com/10.1002/rob.21436},
volume = {29},
year = {2012}
}
@article{Henry2010,
abstract = {RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.},
author = {Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
doi = {10.1177/0278364911434148},
journal = {The International Journal of Robotics Research},
keywords = {RGB-D,SLAM,kinect,localization,mapping,range sensing,vision},
number = {5},
pages = {647--663},
title = {{RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments}},
url = {http://journals.sagepub.com/doi/pdf/10.1177/0278364911434148},
volume = {31},
year = {2010}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@misc{Slamtec,
author = {Slamtec},
title = {{RPLIDAR A2 - Slamtec - Leading Service Robot Localization and Navigation Solution Provider}},
url = {https://www.slamtec.com/en/Lidar/A2},
urldate = {2018-06-18}
}
@article{Ellekilde2007,
author = {Ellekilde, Lars-Peter and Huang, Shoudong and {Valls Mir{\'{o}}}, Jaime and Dissanayake, Gamini},
doi = {10.1002/rob.20173},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {jan},
number = {1-2},
pages = {71--89},
title = {{Dense 3D Map Construction for Indoor Search and Rescue}},
url = {http://doi.wiley.com/10.1002/rob.20173},
volume = {24},
year = {2007}
}
@article{Mangelson2018,
abstract = {— This paper reports on a method for robust se-lection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an " odometry back-bone " to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Max-imization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in real-time. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.},
author = {Mangelson, Joshua G and Dominic, Derrick and Eustice, Ryan M and Vasudevan, Ram},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangelson et al. - Unknown - Pairwise Consistent Measurement Set Maximization for Robust Multi-robot Map Merging(2).pdf:pdf},
isbn = {9781538630808},
journal = {ICRA 2018},
title = {{Pairwise Consistent Measurement Set Maximization for Robust Multi-robot Map Merging}},
url = {http://robots.engin.umich.edu/{~}joshuagm/pubs/jmangelson-2018a.pdf},
year = {2018}
}
@article{Ellekilde2007,
author = {Ellekilde, Lars-Peter and Huang, Shoudong and {Valls Mir{\'{o}}}, Jaime and Dissanayake, Gamini},
doi = {10.1002/rob.20173},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {jan},
number = {1-2},
pages = {71--89},
title = {{Dense 3D Map Construction for Indoor Search and Rescue}},
url = {http://doi.wiley.com/10.1002/rob.20173},
volume = {24},
year = {2007}
}
@inproceedings{Schmuck2017,
abstract = {— With systems performing Simultaneous Localiza-tion And Mapping (SLAM) from a single robot reaching considerable maturity, the possibility of employing a team of robots to collaboratively perform a task has been attracting increasing interest. Promising great impact in a plethora of tasks ranging from industrial inspection to digitization of archaeological structures, collaborative scene perception and mapping are key in efficient and effective estimation. In this paper, we propose a novel, centralized architecture for collaborative monocular SLAM employing multiple small Unmanned Aerial Vehicles (UAVs) to act as agents. Each agent is able to independently explore the environment running limited-memory SLAM onboard, while sending all collected information to a central server, a ground station with increased computational resources. The server manages the maps of all agents, triggering loop closure, map fusion, optimization and distribution of information back to the agents. This allows an agent to incorporate observations from others in its SLAM estimates on the fly. We put the proposed framework to tfile:///home/jungr/Dropbox/AAU/WS17/papers/eth-50606-01(2).pdf he test employing a nominal keyframe-based monocular SLAM algorithm, demonstrating the applicability of this system in multi-UAV scenarios.},
author = {Schmuck, Patrik},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989445},
isbn = {9781509046331},
issn = {10504729},
month = {may},
pages = {3863--3870},
publisher = {IEEE},
title = {{Multi-UAV collaborative monocular SLAM}},
url = {http://ieeexplore.ieee.org/document/7989445/},
year = {2017}
}
@article{Martin2015,
abstract = {This work demonstrates the use of genetic algorithms in optimized view planning for 3D reconstruction applications using small unmanned aerial vehicles (UAVs). The quality of UAV site models is currently highly dependent on manual pilot operations or grid-based automation solutions. When applied to 3D structures, these approaches can result in gaps in the total coverage or inconsistency in final model resolution. Genetic algorithms can effectively explore the search space to locate image positions that produce high quality models in terms of coverage and accuracy. A fitness function is defined, and optimization parameters are selected through semi-exhaustive search. A novel simulation environment for evaluating view plans is demonstrated using terrain generation software. The view planning algorithm is tested in two separate simulation cases: a water drainage structure and a reservoir levee, as representative samples of infrastructure monitoring. The optimized flight plan is compared against three alternate flight plans in each case. The optimized view plan is found to yield terrain models with up to 43{\%} greater accuracy than a standard grid flight pattern, while maintaining comparable coverage and completeness.},
author = {Martin, Ronald and Rojas, Ivan and Franke, Kevin and Hedengren, John},
doi = {10.3390/rs8010026},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin et al. - 2015 - Evolutionary View Planning for Optimized UAV Terrain Modeling in a Simulated Environment.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {UAV,from,genetic algorithm,motion,structure,terrain mapping,view planning},
month = {dec},
number = {1},
pages = {26},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Evolutionary View Planning for Optimized UAV Terrain Modeling in a Simulated Environment}},
url = {http://www.mdpi.com/2072-4292/8/1/26},
volume = {8},
year = {2015}
}
@misc{Intel,
author = {Intel},
title = {{Intel{\textregistered} RealSense™ Depth Camera D435 - Intel{\textregistered} RealSense™ Depth Cameras}},
url = {https://click.intel.com/intelr-realsensetm-depth-camera-d435.html},
urldate = {2018-06-18}
}
@misc{Slamtec,
author = {Slamtec},
title = {{RPLIDAR A2 - Slamtec - Leading Service Robot Localization and Navigation Solution Provider}},
url = {https://www.slamtec.com/en/Lidar/A2},
urldate = {2018-06-18}
}
@article{Hornung2013,
author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1007/s10514-012-9321-0},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornung et al. - 2013 - OctoMap an efficient probabilistic 3D mapping framework based on octrees.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
month = {apr},
number = {3},
pages = {189--206},
publisher = {Springer US},
title = {{OctoMap: an efficient probabilistic 3D mapping framework based on octrees}},
url = {http://link.springer.com/10.1007/s10514-012-9321-0},
volume = {34},
year = {2013}
}
@inproceedings{Labbe2011a,
author = {Labbe, M. and Michaud, F.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6094602},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Memory Management for Real-Time Appearance-Based Loop Closure Detection.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {1271--1276},
publisher = {IEEE},
title = {{Memory management for real-time appearance-based loop closure detection}},
url = {http://ieeexplore.ieee.org/document/6094602/},
year = {2011}
}
@article{Michael2012,
author = {Michael, Nathan and Shen, Shaojie and Mohta, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
doi = {10.1002/rob.21436},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michael et al. - 2012 - Collaborative mapping of an earthquake-damaged building via ground and aerial robots.pdf:pdf},
issn = {15564959},
journal = {Journal of Field Robotics},
month = {sep},
number = {5},
pages = {832--841},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Collaborative mapping of an earthquake-damaged building via ground and aerial robots}},
url = {http://doi.wiley.com/10.1002/rob.21436},
volume = {29},
year = {2012}
}
@inproceedings{Bryson2007,
author = {Bryson, Mitch and Sukkarieh, Salah},
booktitle = {2007 IEEE Aerospace Conference},
doi = {10.1109/AERO.2007.352850},
isbn = {1-4244-0524-6},
pages = {1--12},
publisher = {IEEE},
title = {{Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments}},
url = {http://ieeexplore.ieee.org/document/4161346/},
year = {2007}
}
@article{Labbe2013,
abstract = {In appearance-based localization and mapping, loop- closure detection is the process used to determinate if the cur- rent observation comes from a previously visited location or a new one. As the size of the internal map increases, so does the time required to compare new observations with all stored loca- tions, eventually limiting online processing. This paper presents an online loop-closure detection approach for large-scale and long- term operation. The approach is based on amemorymanagement method,which limits the number of locations used for loop-closure detection so that the computation time remains under real-time constraints. The idea consists of keeping the most recent and fre- quently observed locations in a working memory (WM) that is used for loop-closure detection, and transferring the others into a long-term memory (LTM). When a match is found between the current location and one stored in WM, associated locations that are stored in LTM can be updated and remembered for addi- tional loop-closure detections. Results demonstrate the approach's adaptability and scalability using ten standard datasets from other appearance-based loop-closure approaches, one custom dataset us- ing real images taken over a 2-km loop of our university campus, and one custom dataset (7 h) using virtual images from the racing video game “Need for Speed:MostWanted.”},
author = {Labbe, Mathieu and Michaud, Francois},
doi = {10.1109/TRO.2013.2242375},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labb{\'{e}}, Michaud - Unknown - Appearance-Based Loop Closure Detection for Online Large-Scale and Long-Term Operation.pdf:pdf},
isbn = {978-1-61284-455-8},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Appearance-based localization and mapping,bag-of-words approach,dynamic Bayes filtering,place recognition},
number = {3},
pages = {734--745},
pmid = {6459608},
title = {{Appearance-based loop closure detection for online large-scale and long-term operation}},
url = {https://introlab.3it.usherbrooke.ca/mediawiki-introlab/images/b/bc/TRO2013.pdf},
volume = {29},
year = {2013}
}
@article{Wheeler2017,
author = {Wheeler, David and Koch, Daniel and Jackson, James and Ellingson, Gary and Nyholm, Paul and McLain, Timothy and Beard, Randal},
journal = {All Faculty Publications},
month = {aug},
title = {{Relative Navigation of Autonomous GPS-Degraded Micro Air Vehicles}},
url = {https://scholarsarchive.byu.edu/facpub/1962},
year = {2017}
}
@misc{Velodyne,
author = {Velodyne},
title = {{VLP-16 Velodyne LiDAR}},
url = {http://velodynelidar.com/vlp-16.html},
urldate = {2018-06-18}
}
@article{Zou2013,
abstract = {This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce intercamera pose estimation and intercamera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.},
author = {Zou, Danping and Tan, Ping},
doi = {10.1109/TPAMI.2012.104},
isbn = {2011100712},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Visual SLAM,dynamic environments,structure-from-motion,swarm},
month = {feb},
number = {2},
pages = {354--366},
pmid = {22547430},
title = {{CoSLAM: Collaborative visual SLAM in dynamic environments}},
url = {http://ieeexplore.ieee.org/document/6193110/},
volume = {35},
year = {2013}
}
@misc{Luotsinen2004,
author = {Luotsinen, Linus J and Gonzalez, Avelino J and Boeloeni, Ladislau},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luotsinen, Gonzalez, Boeloeni - 2004 - Collaborative UAV Exploration of Hostile Environments.pdf:pdf},
keywords = {*ALGORITHMS,*AUTONOMOUS NAVIGATION,*COMBAT AREAS,*SURVEILLANCE DRONES,*TACTICAL DATA SYSTEMS,ADVERSE CONDITIONS,ARTIFICIAL INTELLIGENCE,COLLABORATIVE TECHNIQUES,COMPUTERIZED SIMULATION,DECISION MAKING,GRIDS(COORDINATES),INFORMATION TRANSFER,MAPS,SYMPOSIA},
title = {{Collaborative UAV Exploration of Hostile Environments}},
url = {http://www.dtic.mil/docs/citations/ADA432922},
year = {2004}
}
@article{Henry2010a,
abstract = {RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system that utilizes a novel joint optimization algorithm combining visual features and shape-based alignment. Visual and depth information are also combined for view-based loop-closure detection, followed by pose optimization to achieve globally consistent maps. We evaluate RGB-D Mapping on two large indoor environments, and show that it effectively combines the visual and shape information available from RGB-D cameras.},
author = {Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
doi = {10.1177/0278364911434148},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henry et al. - 2010 - RGB-D mapping Using Kinect-style depth cameras for dense 3D modeling of indoor environments.pdf:pdf},
journal = {The International Journal of Robotics Research},
keywords = {RGB-D,SLAM,kinect,localization,mapping,range sensing,vision},
number = {5},
pages = {647--663},
title = {{RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments}},
url = {http://journals.sagepub.com/doi/pdf/10.1177/0278364911434148},
volume = {31},
year = {2010}
}
